{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Python Warapper to Trigger the Azure ML with R steps"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup and get the Dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace, Datastore, Dataset\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core import Environment \n",
        "from azureml.data import OutputFileDatasetConfig\n",
        "\n",
        "#Get default Workspace\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1652909091252
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "#Get the Penguin data from registered Dataset\n",
        "datastore = ws.get_default_datastore()\n",
        "pg_dataset = Dataset.File.from_files(datastore.path('penguin_data'))\n",
        "pg_dataset"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1652909098490
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the Compute and Custom Env"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the Compute\n",
        "compute_name = \"avisekCompute\"\n",
        "compute_target = ws.compute_targets[compute_name]\n",
        "\n",
        "\n",
        "#Get the Custom Env\n",
        "env = Environment.get(ws,name='commandstepR-env')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define and Trigger the Pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.pipeline.core import PipelineData\n",
        "\n",
        "penguin_data = PipelineData(\"penguin_data\", datastore=datastore)\n",
        "#validated_data = PipelineData(\"validated_data\", datastore=datastore)\n",
        "#Define O/P data\n",
        "validated_data = OutputFileDatasetConfig(name=\"validated_data\", destination=(datastore, \"validated_data\")).as_upload(overwrite=True)\n",
        "train_data = OutputFileDatasetConfig(name=\"train_data\", destination=(datastore, \"train_data\")).as_upload(overwrite=True)\n",
        "test_data = OutputFileDatasetConfig(name=\"test_data\", destination=(datastore, \"test_data\")).as_upload(overwrite=True)\n",
        "model = OutputFileDatasetConfig(name=\"model\", destination=(datastore, \"model\")).as_upload(overwrite=True)\n",
        "\n",
        "#Define Source Directory\n",
        "src_dir = './'\n",
        "\n",
        "#Define the Rscripts\n",
        "process_data = ScriptRunConfig(source_directory=src_dir,\n",
        "                            command=['Rscript process_data.R --penguin_data', pg_dataset.as_named_input(name=\"penguin_data\").as_mount(), '--output_folder', validated_data],\n",
        "                            compute_target=compute_target,\n",
        "                            environment=env)\n",
        "\n",
        "prepare_data = ScriptRunConfig(source_directory=src_dir,\n",
        "                            command=['Rscript prepare_data.R --validated_data', validated_data, '--train_folder', train_data, '--test_folder', test_data],\n",
        "                            compute_target=compute_target,\n",
        "                            environment=env)\n",
        "\n",
        "train = ScriptRunConfig(source_directory=src_dir,\n",
        "                            command=['Rscript train_model_dt.R --train_data', train_data, '--model_folder', model],\n",
        "                            compute_target=compute_target,\n",
        "                            environment=env)\n",
        "\n",
        "test = ScriptRunConfig(source_directory=src_dir,\n",
        "                            command=['Rscript test_model_dt.R --test_data', test_data, '--model_folder', model],\n",
        "                            compute_target=compute_target,\n",
        "                            environment=env)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1652893212968
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import CommandStep\n",
        "\n",
        "#Define Pipeline Steps\n",
        "#Process Data step\n",
        "process_data_step = CommandStep(name='process_data', \n",
        "                    outputs = [validated_data],\n",
        "                    runconfig=process_data)\n",
        "#Prepare/Feature Engg step\n",
        "prepare_data_step = CommandStep(name='prepare_data', \n",
        "                    inputs = [validated_data],\n",
        "                    outputs = [train_data, test_data],\n",
        "                    runconfig=prepare_data)\n",
        "#Train the Model\n",
        "train_step = CommandStep(name='model_training', \n",
        "                    inputs = [train_data],\n",
        "                    outputs = [model],\n",
        "                    runconfig=train)\n",
        "#Test the model\n",
        "test_step = CommandStep(name='model_scoring', \n",
        "                    inputs = [test_data, model],\n",
        "                    #outputs = [model],\n",
        "                    runconfig=test)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1652893213137
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of steps to run (`compare_step` definition not shown)\n",
        "poc_pipeline_R = [test_step]\n",
        "\n",
        "from azureml.pipeline.core import Pipeline\n",
        "\n",
        "# Build the pipeline\n",
        "pipeline1 = Pipeline(workspace=ws, steps=[poc_pipeline_R])\n",
        "\n",
        "\n",
        "\n",
        "from azureml.core import Experiment\n",
        "\n",
        "# Submit the pipeline to be run\n",
        "pipeline_run1 = Experiment(ws, 'POC_PENGUIN_DATA_CMDSTEP').submit(pipeline1)\n",
        "pipeline_run1.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1652893494631
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register the Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model\n",
        "import os\n",
        "\n",
        "datastore.download(os.getcwd(), prefix='model/model_dt.rds', overwrite = True)\n",
        "\n",
        "#Get the working Dir\n",
        "wkDir  = os.getcwd()\n",
        "# Name of the create Directory\n",
        "dataDir = \"model/model_dt.rds\"  \n",
        "# Path\n",
        "path = os.path.join(wkDir, dataDir)\n",
        "\n",
        "myModel = Model.register(model_path=path,\n",
        "                          model_name=\"decision_tree_model\",\n",
        "                          tags={'area': \"penguin data\", 'type': \"classification\"},\n",
        "                          description=\"Decision Tree model to predict Penguin Species\",\n",
        "                          workspace=ws)\n",
        "\n",
        "print('Name:', myModel.name)\n",
        "print('Version:', myModel.version)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1652909311669
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}